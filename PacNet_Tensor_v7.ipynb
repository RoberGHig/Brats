{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:\\\\Users\\\\rober\\\\Practicas\\\\training\\\\training_v2.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue):\n",
    "    #Definimos la ruta de los tfrecords\n",
    "    filename = 'C:\\\\Users\\\\rober\\\\Practicas\\\\training\\\\training_v2.tfrecords'\n",
    "    feature={\n",
    "        'image/encoded': tf.FixedLenFeature([], tf.string,default_value=''),\n",
    "        'label/encoded': tf.FixedLenFeature([], tf.string,default_value='')\n",
    "    }\n",
    "    #Función encargada de añadir a una cola FIFO la lista de ficheros, además el parametro epochs\n",
    "    #nos proporciona el numero de tensores que obtendremos en cada iteracción\n",
    "    filename_queue = tf.train.string_input_producer([filename], num_epochs=1)\n",
    "    #Definimos un lector\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    #Diccionario con las características necesarias.Decodificamos el \"record\" leido\n",
    "    #por el lector\n",
    "    #features = tf.parse_single_example(serialized_example,)  \n",
    "    # Nos devuelve la imagen y la etiqueta\n",
    "    #Convierte la etiqueta a su formato original \n",
    "    with tf.name_scope('label'):\n",
    "        label = tf.decode_raw(features['label/encoded'], tf.float32)\n",
    "        label = tf.transpose(tf.reshape(label, [1,240,240]), (0,2,1))\n",
    "    #Convierte la imagen a su formato original \n",
    "    with tf.name_scope('image'):\n",
    "        image = tf.decode_raw(features['image/encoded'], tf.float32)\n",
    "        image = tf.transpose(tf.reshape(image, [4,240,240]), (0,2,1))\n",
    "        #image = tf.reshape(image, [32, 100, 3])\n",
    "    #Realiza el casteo a float32 e int32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label = tf.one_hot(indices=label,depth=5,on_value=1,off_value=0,)\n",
    "    print(\"image\", image.get_shape(), label.get_shape())\n",
    "    \n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(batch_size,num_epochs,filename):\n",
    "    if not num_epochs: num_epochs = None\n",
    "    with tf.name_scope('input'):\n",
    "        filename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs)\n",
    "        image, label = read_and_decode(filename_queue=filename_queue)\n",
    "        images, sparse_labels = tf.train.shuffle_batch(\n",
    "        [image, label], batch_size=batch_size, num_threads=2,\n",
    "        capacity=15,\n",
    "        min_after_dequeue=10)\n",
    "        return images, sparse_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "def maxpool2d(x, kernel_size=3,strides=1):\n",
    "    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1], \n",
    "                          strides=[1, strides, strides, 1],padding='SAME')\n",
    "def deconv2d(x,W,output_shape,strides=1):\n",
    "    return tf.nn.conv2d_transpose(x,W,output_shape,strides=[1,strides,strides,1],padding='SAME')\n",
    "def print_tensor_shape(tensor,string):\n",
    "    print(string,tensor.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits,labels):\n",
    "        labels = tf.to_int64(labels)\n",
    "        print_tensor_shape(logits,\"Logits antes del reshape: \")\n",
    "        print_tensor_shape(labels,\"Labels antes del reshape: \")\n",
    "        #OJO CON EL NUMERO DE CLASES [-1,NUMERO CLASES]\n",
    "        logits_re = tf.reshape(logits,[-1,5])\n",
    "        labels_re = tf.reshape(labels,[-1])\n",
    "        print_tensor_shape(logits_re,\"Logits despues del reshape: \")\n",
    "        print_tensor_shape(labels_re,\"Labels despues del reshape: \")\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_re,logits=logits_re,\n",
    "                                                                       name='cross_entropy')\n",
    "        loss = tf.reduce_mean(cross_entropy,name='cross_entropy_mean')\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(loss,learning_rate,decay_steps,decay_rate):\n",
    "    tf.summary.scalar(loss.op.name,loss)\n",
    "    global_step = tf.Variable(0,name='global_step',trainable=False)\n",
    "    lr = tf.train.exponential_decay(learning_rate,\n",
    "                                   global_step,\n",
    "                                   decay_steps,\n",
    "                                   decay_rate,\n",
    "                                   staircase=True)\n",
    "    tf.summary.scalar('learning_rate',lr)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    train_op=optimizer.minimize(loss,global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    #PESOS DEL PATH SMALL\n",
    "    # 3x3 conv, 4 input, 64 outputs\n",
    "    'w_s1': tf.Variable(tf.random_normal([3, 3, 4, 64])),\n",
    "    # 3x3 conv, 64 inputs, 64 outputs\n",
    "    'w_s2': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "    # 3x3 conv, 64 inputs, 64 outputs\n",
    "    'w_s3': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "    # 3x3 conv, 64 inputs, 64 outputs\n",
    "    'w_s4': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "    # 3x3 conv, 64 inputs, 64 outputs\n",
    "    'w_s5': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "    # 3x3 conv, 4 input, 64 outputs\n",
    "    'w_s6': tf.Variable(tf.random_normal([3, 3, 4, 64])),\n",
    "    # 3x3 conv, 64 inputs, 64 outputs\n",
    "    'w_s7': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "    # 3x3 conv, 64 inputs, 64 outputs\n",
    "    'w_s8': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "    # 3x3 conv, 64 inputs, 64 outputs\n",
    "    'w_s9': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "    \n",
    "    #PESOS DEL PATH MEDIUM\n",
    "    # 7x7 conv, 4 input, 128 outputs\n",
    "    'w_m1': tf.Variable(tf.random_normal([7, 7, 4, 128])),\n",
    "    # 7x7 conv, 128 inputs, 128 outputs\n",
    "    'w_m2': tf.Variable(tf.random_normal([7, 7, 128, 128])),\n",
    "    # 7x7 conv, 128 inputs, 128 outputs\n",
    "    'w_m3': tf.Variable(tf.random_normal([7, 7, 128, 128])),\n",
    "    # 7x7 conv, 128 inputs, 128 outputs\n",
    "    'w_m4': tf.Variable(tf.random_normal([7, 7, 128, 128])),\n",
    "    # 7x7 conv, 128 inputs, 128 outputs\n",
    "    'w_m5': tf.Variable(tf.random_normal([7, 7, 128, 128])),\n",
    "    # 7x7 conv, 4 input, 128 outputs\n",
    "    'w_m6': tf.Variable(tf.random_normal([7, 7, 4, 128])),\n",
    "    # 7x7 conv, 128 inputs, 128 outputs\n",
    "    'w_m7': tf.Variable(tf.random_normal([7, 7, 128, 128])),\n",
    "    # 7x7 conv, 128 inputs, 128 outputs\n",
    "    'w_m8': tf.Variable(tf.random_normal([7, 7, 128, 128])),\n",
    "    # 7x7 conv, 128 inputs, 128 outputs\n",
    "    'w_m9': tf.Variable(tf.random_normal([7, 7, 128, 128])),\n",
    "    \n",
    "    #PESOS DEL PATH LARGE\n",
    "    # 11x11 conv, 4 input, 256 outputs\n",
    "    'w_l1': tf.Variable(tf.random_normal([11,11, 4, 256])),\n",
    "    # 11x11 conv, 256 inputs, 256 outputs\n",
    "    'w_l2': tf.Variable(tf.random_normal([11, 11, 256, 256])),\n",
    "    # 11x11 conv, 256 inputs, 256 outputs\n",
    "    'w_l3': tf.Variable(tf.random_normal([11, 11, 256, 256])),\n",
    "    # 11x11 conv, 256 inputs, 256 outputs\n",
    "    'w_l4': tf.Variable(tf.random_normal([11, 11, 256, 256])),\n",
    "    # 11x11 conv, 256 inputs, 256 outputs\n",
    "    'w_l5': tf.Variable(tf.random_normal([11, 11, 256, 256])),\n",
    "    # 11x11 conv, 4 input, 256 outputs\n",
    "    'w_l6': tf.Variable(tf.random_normal([11,11, 4, 256])),\n",
    "    # 11x11 conv, 256 inputs, 256 outputs\n",
    "    'w_l7': tf.Variable(tf.random_normal([11, 11, 256, 256])),\n",
    "    # 11x11 conv, 256 inputs, 256 outputs\n",
    "    'w_l8': tf.Variable(tf.random_normal([11, 11, 256, 256])),\n",
    "    # 11x11 conv, 256 inputs, 256 outputs\n",
    "    'w_l9': tf.Variable(tf.random_normal([11, 11, 256, 256])),\n",
    "    \n",
    "    #PESOS DEL PATH FUSION\n",
    "    # 1x1 conv, 448 inputs, 300 outputs\n",
    "    'w_f1': tf.Variable(tf.random_normal([1, 1, 448, 300])),\n",
    "    # 1x1 conv, 300 inputs, 512 outputs\n",
    "    'w_f2': tf.Variable(tf.random_normal([1, 1, 300, 512])),\n",
    "    # 1x1 conv, 512 inputs, 5 outputs\n",
    "    'w_f3': tf.Variable(tf.random_normal([1, 1, 512, 5])),\n",
    "    # 3x3 conv, 448 inputs, 300 outputs\n",
    "    'w_f4': tf.Variable(tf.random_normal([3, 3, 448, 300])),\n",
    "    # 1x1 conv, 300 inputs, 512 outputs\n",
    "    'w_f5': tf.Variable(tf.random_normal([1, 1, 300, 512])),\n",
    "    # 1x1 conv, 512 inputs, 5 outputs\n",
    "    'w_f6': tf.Variable(tf.random_normal([1, 1, 512, 5])),\n",
    "    \n",
    "    #PESOS DEL PATH DECONVOLUCIONAL\n",
    "    # 1x1 conv, 5 inputs, 5 outputs\n",
    "    'w_fdec1': tf.Variable(tf.random_normal([1, 1, 5, 5])),\n",
    "    # 1x1 conv, 5 inputs, 5 outputs\n",
    "    'w_fdec2': tf.Variable(tf.random_normal([1, 1, 5, 5])),\n",
    "    \n",
    "    #PESOS DEL PATH FINAL FUSION\n",
    "    # 1x1 conv, 10 inputs, 5 outputs\n",
    "    'w_final_fusion': tf.Variable(tf.random_normal([1, 1, 10, 5])),\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "biases = {\n",
    "    #BIASES DEL PATH SMALL\n",
    "    'b_s_1': tf.Variable(tf.random_normal([64])),\n",
    "    'b_s_2': tf.Variable(tf.random_normal([64])),\n",
    "    'b_s_3': tf.Variable(tf.random_normal([64])),\n",
    "    'b_s_4': tf.Variable(tf.random_normal([64])),\n",
    "    'b_s_5': tf.Variable(tf.random_normal([64])),\n",
    "    'b_s_6': tf.Variable(tf.random_normal([64])),\n",
    "    'b_s_7': tf.Variable(tf.random_normal([64])),\n",
    "    'b_s_8': tf.Variable(tf.random_normal([64])),\n",
    "    'b_s_9': tf.Variable(tf.random_normal([64])),\n",
    "    \n",
    "    #BIASES DEL PATH MEDIUM\n",
    "    'b_m_1': tf.Variable(tf.random_normal([128])),\n",
    "    'b_m_2': tf.Variable(tf.random_normal([128])),\n",
    "    'b_m_3': tf.Variable(tf.random_normal([128])),\n",
    "    'b_m_4': tf.Variable(tf.random_normal([128])),\n",
    "    'b_m_5': tf.Variable(tf.random_normal([128])),\n",
    "    'b_m_6': tf.Variable(tf.random_normal([128])),\n",
    "    'b_m_7': tf.Variable(tf.random_normal([128])),\n",
    "    'b_m_8': tf.Variable(tf.random_normal([128])),\n",
    "    'b_m_9': tf.Variable(tf.random_normal([128])),\n",
    "    \n",
    "    #BIASES DEL PATH LARGE\n",
    "    'b_l_1': tf.Variable(tf.random_normal([256])),\n",
    "    'b_l_2': tf.Variable(tf.random_normal([256])),\n",
    "    'b_l_3': tf.Variable(tf.random_normal([256])),\n",
    "    'b_l_4': tf.Variable(tf.random_normal([256])),\n",
    "    'b_l_5': tf.Variable(tf.random_normal([256])),\n",
    "    'b_l_6': tf.Variable(tf.random_normal([256])),\n",
    "    'b_l_7': tf.Variable(tf.random_normal([256])),\n",
    "    'b_l_8': tf.Variable(tf.random_normal([256])),\n",
    "    'b_l_9': tf.Variable(tf.random_normal([256])),\n",
    "    \n",
    "    #BIASES DEL PATH FUSION\n",
    "    'b_f_1': tf.Variable(tf.random_normal([300])),\n",
    "    'b_f_2': tf.Variable(tf.random_normal([512])),\n",
    "    'b_f_3': tf.Variable(tf.random_normal([5])),\n",
    "    'b_f_4': tf.Variable(tf.random_normal([300])),\n",
    "    'b_f_5': tf.Variable(tf.random_normal([512])),\n",
    "    'b_f_6': tf.Variable(tf.random_normal([5])),\n",
    "    \n",
    "    #BIASES DEL PATH FINAL FUSION\n",
    "    'b_ff': tf.Variable(tf.random_normal([5]))\n",
    "}\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(x,weights,biases,dropout):\n",
    "    print_tensor_shape(x,'X antes del Reshaping')\n",
    "    #x = tf.reshape(x, shape=[-1, 240, 240, 4])\n",
    "    x = tf.reshape(x,[batch_size,240,240,-1])\n",
    "    print_tensor_shape(x,'X despues del Reshaping')\n",
    "    print(\"\\n\")\n",
    "    #WHERE\n",
    "    #SMALL\n",
    "    conv1 = conv2d(x,weights['w_s1'],biases['b_s_1'],strides=1)\n",
    "    print_tensor_shape(conv1,'Shape conv1')\n",
    "    pool1 = maxpool2d(conv1,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool1,'Shape pool1')\n",
    "    conv2 = conv2d(pool1,weights['w_s2'],biases['b_s_2'],strides=1)\n",
    "    print_tensor_shape(conv2,'Shape conv2')\n",
    "    pool2 = maxpool2d(conv2,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool2,'Shape pool2')\n",
    "    conv3 = conv2d(pool2,weights['w_s3'],biases['b_s_3'],strides=1)\n",
    "    print_tensor_shape(conv3,'Shape conv3')\n",
    "    pool3 = maxpool2d(conv3,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool3,'Shape pool3')\n",
    "    conv4 = conv2d(pool3,weights['w_s4'],biases['b_s_4'],strides=1)\n",
    "    print_tensor_shape(conv4,'Shape conv4')\n",
    "    pool4 = maxpool2d(conv4,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool4,'Shape pool4')\n",
    "    conv5 = conv2d(pool4,weights['w_s5'],biases['b_s_5'],strides=1)\n",
    "    print_tensor_shape(conv5,'Shape conv5')\n",
    "    pool5 = maxpool2d(conv5,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool5,'Shape pool5')\n",
    "    print(\"\\n\")\n",
    "    #MEDIUM\n",
    "    conv6 = conv2d(x,weights['w_m1'],biases['b_m_1'],strides=1)\n",
    "    print_tensor_shape(conv6,'Shape conv6')\n",
    "    pool6 = maxpool2d(conv6,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool6,'Shape pool6')\n",
    "    conv7 = conv2d(pool6,weights['w_m2'],biases['b_m_2'],strides=1)\n",
    "    print_tensor_shape(conv7,'Shape conv7')\n",
    "    pool7 = maxpool2d(conv7,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool7,'Shape pool7')\n",
    "    conv8 = conv2d(pool7,weights['w_m3'],biases['b_m_3'],strides=1)\n",
    "    print_tensor_shape(conv8,'Shape conv8')\n",
    "    pool8 = maxpool2d(conv8,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool8,'Shape pool8')\n",
    "    conv9 = conv2d(pool8,weights['w_m4'],biases['b_m_4'],strides=1)\n",
    "    print_tensor_shape(conv9,'Shape conv9')\n",
    "    pool9 = maxpool2d(conv9,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool9,'Shape pool9')\n",
    "    conv10 = conv2d(pool9,weights['w_m5'],biases['b_m_5'],strides=1)\n",
    "    print_tensor_shape(conv10,'Shape conv10')\n",
    "    pool10 = maxpool2d(conv10,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool10,'Shape pool10')\n",
    "    print(\"\\n\")\n",
    "    #LARGE\n",
    "    conv11 = conv2d(x,weights['w_l1'],biases['b_l_1'],strides=1)\n",
    "    print_tensor_shape(conv11,'Shape conv11')\n",
    "    pool11 = maxpool2d(conv11,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool11,'Shape pool11')\n",
    "    conv12 = conv2d(pool11,weights['w_l2'],biases['b_l_2'],strides=1)\n",
    "    print_tensor_shape(conv12,'Shape conv12')\n",
    "    pool12 = maxpool2d(conv12,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool12,'Shape pool12')\n",
    "    conv13 = conv2d(pool12,weights['w_l3'],biases['b_l_3'],strides=1)\n",
    "    print_tensor_shape(conv13,'Shape conv13')\n",
    "    pool13 = maxpool2d(conv13,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool11,'Shape pool13')\n",
    "    conv14 = conv2d(pool13,weights['w_l4'],biases['b_l_4'],strides=1)\n",
    "    print_tensor_shape(conv12,'Shape conv14')\n",
    "    pool14 = maxpool2d(conv14,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool14,'Shape pool14')\n",
    "    conv15 = conv2d(pool14,weights['w_l5'],biases['b_l_5'],strides=1)\n",
    "    print_tensor_shape(conv15,'Shape conv15')\n",
    "    pool15 = maxpool2d(conv15,kernel_size=3,strides=1)\n",
    "    print_tensor_shape(pool14,'Shape pool15')\n",
    "    print(\"\\n\")\n",
    "    #FUSION\n",
    "    conv16 = tf.concat((pool5,pool10,pool15),3)\n",
    "    print_tensor_shape(conv16,'Shape conv16_concat')\n",
    "    conv16 = conv2d(conv16,weights['w_f1'],biases['b_f_1'],strides=1)\n",
    "    print_tensor_shape(conv16,'Shape conv16')\n",
    "    drop1 = tf.nn.dropout(conv16,dropout)\n",
    "    print_tensor_shape(drop1,'Shape drop1')\n",
    "    conv17 = conv2d(drop1,weights['w_f2'],biases['b_f_2'],strides=1)\n",
    "    print_tensor_shape(conv17,'Shape conv17')\n",
    "    drop2 = tf.nn.dropout(conv17,dropout)\n",
    "    print_tensor_shape(drop2,'Shape drop2')\n",
    "    conv18 = conv2d(drop2,weights['w_f3'],biases['b_f_3'],strides=1)\n",
    "    print_tensor_shape(conv18,'Shape conv18')\n",
    "    print(\"\\n\")\n",
    "    #WHAT\n",
    "    #LARGE\n",
    "    conv1l =conv2d(x,weights['w_l6'],biases['b_l_6'],strides=1)\n",
    "    print_tensor_shape(conv1l,'Shape conv1l')\n",
    "    pool1l= maxpool2d(conv1l,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool1l,'Shape pool1l')\n",
    "    conv2l =conv2d(pool1l,weights['w_l7'],biases['b_l_7'],strides=1)\n",
    "    print_tensor_shape(conv2l,'Shape conv2l')\n",
    "    pool2l= maxpool2d(conv2l,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool2l,'Shape pool2l')\n",
    "    conv3l =conv2d(pool2l,weights['w_l8'],biases['b_l_8'],strides=1)\n",
    "    print_tensor_shape(conv3l,'Shape conv3l')\n",
    "    pool3l= maxpool2d(conv3l,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool3l,'Shape pool3l')\n",
    "    conv4l =conv2d(pool3l,weights['w_l9'],biases['b_l_9'],strides=1)\n",
    "    print_tensor_shape(conv4l,'Shape conv4l')\n",
    "    print(\"\\n\")\n",
    "    #MEDIUM\n",
    "    conv1m =conv2d(x,weights['w_m6'],biases['b_m_6'],strides=1)\n",
    "    print_tensor_shape(conv1m,'Shape conv1m')\n",
    "    pool1m= maxpool2d(conv1m,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool1m,'Shape pool1m')\n",
    "    conv2m = conv2d(pool1m,weights['w_m7'],biases['b_m_7'],strides=1)\n",
    "    print_tensor_shape(conv2m,'Shape conv2m')\n",
    "    pool2m= maxpool2d(conv2m,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool2m,'Shape pool2m')\n",
    "    conv3m = conv2d(pool2m,weights['w_m8'],biases['b_m_8'],strides=1)\n",
    "    print_tensor_shape(conv3m,'Shape conv3m')\n",
    "    pool3m= maxpool2d(conv3m,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool3m,'Shape pool3m')\n",
    "    conv4m = conv2d(pool3m,weights['w_m9'],biases['b_m_9'],strides=1)\n",
    "    print_tensor_shape(conv4m,'Shape conv4m')\n",
    "    print(\"\\n\")\n",
    "    #SMALL\n",
    "    conv1s =conv2d(x,weights['w_s6'],biases['b_s_6'],strides=1)\n",
    "    print_tensor_shape(conv1s,'Shape conv1s')\n",
    "    pool1s= maxpool2d(conv1s,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool1s,'Shape pool1s')\n",
    "    conv2s = conv2d(pool1s,weights['w_s7'],biases['b_s_7'],strides=1)\n",
    "    print_tensor_shape(conv2s,'Shape conv2s')\n",
    "    pool2s= maxpool2d(conv2s,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool2s,'Shape pool2s')\n",
    "    conv3s = conv2d(pool2s,weights['w_s8'],biases['b_s_8'],strides=1)\n",
    "    print_tensor_shape(conv3s,'Shape conv3s')\n",
    "    pool3s= maxpool2d(conv3s,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(pool3s,'Shape pool3s')\n",
    "    conv4s = conv2d(pool3s,weights['w_s9'],biases['b_s_9'],strides=1)\n",
    "    print_tensor_shape(conv4s,'Shape conv4s')\n",
    "    print(\"\\n\")\n",
    "    #FUSION\n",
    "    convf1 = tf.concat((conv4l,conv4m,conv4s),3) \n",
    "    print_tensor_shape(convf1,'Shape convf1')\n",
    "    convf2 = conv2d(convf1,weights['w_f4'],biases['b_f_4'],strides=1)\n",
    "    print_tensor_shape(convf2,'Shape convf2')\n",
    "    poolf2= maxpool2d(convf2,kernel_size=2,strides=2)\n",
    "    print_tensor_shape(poolf2,'Shape poolf2')\n",
    "    dropf3 = tf.nn.dropout(poolf2,dropout)\n",
    "    print_tensor_shape(dropf3,'Shape dropf3')\n",
    "    convf4 = conv2d(dropf3,weights['w_f5'],biases['b_f_5'],strides=1)\n",
    "    print_tensor_shape(convf4,'Shape convf4')\n",
    "    dropf5 = tf.nn.dropout(convf4,dropout)\n",
    "    print_tensor_shape(dropf5,'Shape dropf5')\n",
    "    convf5 = conv2d(dropf5,weights['w_f6'],biases['b_f_6'],strides=1)\n",
    "    print_tensor_shape(convf5,'Shape convf5')\n",
    "    print(\"\\n\")\n",
    "    #DECONV\n",
    "    deconv1= deconv2d(convf5,weights['w_fdec1'],output_shape = [batch_size,60,60,5],strides=4)\n",
    "    print_tensor_shape(deconv1,'Shape deconv1')\n",
    "    deconv2 = deconv2d(deconv1,weights['w_fdec2'],output_shape = [batch_size,240,240,5],strides=4)\n",
    "    print_tensor_shape(deconv2,'Shape deconv2')\n",
    "    print(\"\\n\")\n",
    "    #FINAL FUSION\n",
    "    conv_final_fusion1 = tf.concat((conv18,deconv2),3)\n",
    "    print_tensor_shape(conv_final_fusion1,'Shape conv_final_fusion1')\n",
    "    conv_final_fusion2 = conv2d(conv_final_fusion1,weights['w_final_fusion'],biases['b_ff'],strides=1)\n",
    "    print_tensor_shape(conv_final_fusion2,'Shape conv_final_fusion2')\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return conv_final_fusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "decay_rate = 1.0\n",
    "decay_steps = 1000\n",
    "num_epochs = 2\n",
    "batch_size = 1\n",
    "num_input = 240*240\n",
    "filename = 'C:\\\\Users\\\\rober\\\\Practicas\\\\training\\\\training_v2.tfrecords'\n",
    "checkpoint = 'C:\\\\Users\\\\rober\\\\Practicas\\\\training\\\\checkpoint'\n",
    "X = tf.placeholder(tf.float32, [None, num_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    images = tf.placeholder(tf.float32, [None, num_input])\n",
    "    labels = tf.placeholder(tf.float32,[None,1])\n",
    "    images,labels = inputs(batch_size,num_epochs,filename)\n",
    "    print_tensor_shape(images,'Images Despues de la funcion inputs')\n",
    "    labels = tf.reshape(labels,[batch_size,240,240,-1])\n",
    "    print_tensor_shape(labels,'Labels Despues del reshape')\n",
    "\n",
    "\n",
    "    results = net(images,weights,biases,dropout)\n",
    "    print_tensor_shape(results,'RESULTADOS_SHAPE')\n",
    "    print_tensor_shape(labels,'LABELSSSS')\n",
    "    \n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels,logits=results,\n",
    "                                                                       name='cross_entropy')\n",
    "    perdidas = tf.reduce_mean(cross_entropy,name='cross_entropy_mean')\n",
    "    #perdidas = loss(results,labels)\n",
    "    print_tensor_shape(perdidas,'PERRDDDIIDDASSs')\n",
    "    print('PERDIDAS',perdidas)\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(perdidas)\n",
    "    print('TRAIN STEP',train_step)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #train_op = training(perdidas,learning_rate,decay_steps,decay_rate)\n",
    "    summary_op =tf.summary.merge_all()\n",
    "    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    sess =tf.Session()\n",
    "    summary_writer = tf.summary.FileWriter(checkpoint,sess.graph)\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    #_,loss_value = sess.run([train_op,perdidas])\n",
    "    try:\n",
    "        step = 0\n",
    "        while not coord.should_stop():\n",
    "            start_time = time.time()\n",
    "            _,loss_value = sess.run([train_step,perdidas])\n",
    "            print(\"Aqui llega\\n\\n\\n\")\n",
    "            duration = time.time()-start_time\n",
    "            if step % 100 == 0:\n",
    "                print('OUTPUT:Step %d: loss = %.3f (%.3f sec)' % (step,loss_value,duration))\n",
    "                summary_str = sess.run(summary_op)\n",
    "                summary_writer.add_summary(summary_str,step)\n",
    "                summary_writer.flush()\n",
    "            if step % 1000 == 0:\n",
    "                checkpoint_path = os.path.join(checkpoint,'model.ckpt')\n",
    "                saver.save(sess,checkpoint_path,global_step = step)\n",
    "            step +=1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('OUTPUT: Done training for %d epochs, %d steps',num_epochs,step)\n",
    "        checkpoint_path = os.path.join(checkpoint,'model.ckpt')\n",
    "        saver.save(sess,checkpoint_path,global_step = step)\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image (4, 240, 240) (1, 240, 240, 5)\n",
      "Images Despues de la funcion inputs (1, 4, 240, 240)\n",
      "Labels Despues del reshape (1, 240, 240, 5)\n",
      "X antes del Reshaping (1, 4, 240, 240)\n",
      "X despues del Reshaping (1, 240, 240, 4)\n",
      "\n",
      "\n",
      "Shape conv1 (1, 240, 240, 64)\n",
      "Shape pool1 (1, 240, 240, 64)\n",
      "Shape conv2 (1, 240, 240, 64)\n",
      "Shape pool2 (1, 240, 240, 64)\n",
      "Shape conv3 (1, 240, 240, 64)\n",
      "Shape pool3 (1, 240, 240, 64)\n",
      "Shape conv4 (1, 240, 240, 64)\n",
      "Shape pool4 (1, 240, 240, 64)\n",
      "Shape conv5 (1, 240, 240, 64)\n",
      "Shape pool5 (1, 240, 240, 64)\n",
      "\n",
      "\n",
      "Shape conv6 (1, 240, 240, 128)\n",
      "Shape pool6 (1, 240, 240, 128)\n",
      "Shape conv7 (1, 240, 240, 128)\n",
      "Shape pool7 (1, 240, 240, 128)\n",
      "Shape conv8 (1, 240, 240, 128)\n",
      "Shape pool8 (1, 240, 240, 128)\n",
      "Shape conv9 (1, 240, 240, 128)\n",
      "Shape pool9 (1, 240, 240, 128)\n",
      "Shape conv10 (1, 240, 240, 128)\n",
      "Shape pool10 (1, 240, 240, 128)\n",
      "\n",
      "\n",
      "Shape conv11 (1, 240, 240, 256)\n",
      "Shape pool11 (1, 240, 240, 256)\n",
      "Shape conv12 (1, 240, 240, 256)\n",
      "Shape pool12 (1, 240, 240, 256)\n",
      "Shape conv13 (1, 240, 240, 256)\n",
      "Shape pool13 (1, 240, 240, 256)\n",
      "Shape conv14 (1, 240, 240, 256)\n",
      "Shape pool14 (1, 240, 240, 256)\n",
      "Shape conv15 (1, 240, 240, 256)\n",
      "Shape pool15 (1, 240, 240, 256)\n",
      "\n",
      "\n",
      "Shape conv16_concat (1, 240, 240, 448)\n",
      "Shape conv16 (1, 240, 240, 300)\n",
      "Shape drop1 (1, 240, 240, 300)\n",
      "Shape conv17 (1, 240, 240, 512)\n",
      "Shape drop2 (1, 240, 240, 512)\n",
      "Shape conv18 (1, 240, 240, 5)\n",
      "\n",
      "\n",
      "Shape conv1l (1, 240, 240, 256)\n",
      "Shape pool1l (1, 120, 120, 256)\n",
      "Shape conv2l (1, 120, 120, 256)\n",
      "Shape pool2l (1, 60, 60, 256)\n",
      "Shape conv3l (1, 60, 60, 256)\n",
      "Shape pool3l (1, 30, 30, 256)\n",
      "Shape conv4l (1, 30, 30, 256)\n",
      "\n",
      "\n",
      "Shape conv1m (1, 240, 240, 128)\n",
      "Shape pool1m (1, 120, 120, 128)\n",
      "Shape conv2m (1, 120, 120, 128)\n",
      "Shape pool2m (1, 60, 60, 128)\n",
      "Shape conv3m (1, 60, 60, 128)\n",
      "Shape pool3m (1, 30, 30, 128)\n",
      "Shape conv4m (1, 30, 30, 128)\n",
      "\n",
      "\n",
      "Shape conv1s (1, 240, 240, 64)\n",
      "Shape pool1s (1, 120, 120, 64)\n",
      "Shape conv2s (1, 120, 120, 64)\n",
      "Shape pool2s (1, 60, 60, 64)\n",
      "Shape conv3s (1, 60, 60, 64)\n",
      "Shape pool3s (1, 30, 30, 64)\n",
      "Shape conv4s (1, 30, 30, 64)\n",
      "\n",
      "\n",
      "Shape convf1 (1, 30, 30, 448)\n",
      "Shape convf2 (1, 30, 30, 300)\n",
      "Shape poolf2 (1, 15, 15, 300)\n",
      "Shape dropf3 (1, 15, 15, 300)\n",
      "Shape convf4 (1, 15, 15, 512)\n",
      "Shape dropf5 (1, 15, 15, 512)\n",
      "Shape convf5 (1, 15, 15, 5)\n",
      "\n",
      "\n",
      "Shape deconv1 (1, 60, 60, 5)\n",
      "Shape deconv2 (1, 240, 240, 5)\n",
      "\n",
      "\n",
      "Shape conv_final_fusion1 (1, 240, 240, 10)\n",
      "Shape conv_final_fusion2 (1, 240, 240, 5)\n",
      "\n",
      "\n",
      "RESULTADOS_SHAPE (1, 240, 240, 5)\n",
      "LABELSSSS (1, 240, 240, 5)\n",
      "PERRDDDIIDDASSs ()\n",
      "PERDIDAS Tensor(\"cross_entropy_mean_2:0\", shape=(), dtype=float32)\n",
      "TRAIN STEP name: \"Adam_2\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam_2/update_Variable_70/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_71/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_72/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_73/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_74/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_75/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_76/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_77/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_78/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_79/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_80/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_81/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_82/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_83/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_84/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_85/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_86/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_87/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_88/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_89/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_90/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_91/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_92/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_93/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_94/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_95/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_96/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_97/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_98/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_99/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_100/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_101/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_102/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_103/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_104/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_105/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_106/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_107/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_108/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_109/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_110/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_111/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_112/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_113/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_114/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_115/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_116/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_117/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_118/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_119/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_120/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_121/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_122/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_123/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_124/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_125/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_126/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_127/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_128/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_129/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_130/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_131/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_132/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_133/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_134/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_135/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_136/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_137/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_138/ApplyAdam\"\n",
      "input: \"^Adam_2/update_Variable_139/ApplyAdam\"\n",
      "input: \"^Adam_2/Assign\"\n",
      "input: \"^Adam_2/Assign_1\"\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,4,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Variable_70/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_70/Assign\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_70/Adam, Variable_70/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Variable_70/Adam/Assign', defined at:\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tornado\\ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-e590fa8f669f>\", line 1, in <module>\n    main(_)\n  File \"<ipython-input-36-288a7b198bb2>\", line 2, in main\n    run_training()\n  File \"<ipython-input-35-b48a4403a598>\", line 20, in run_training\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(perdidas)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 424, in minimize\n    name=name)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 600, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 1150, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 181, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 155, in create_slot_with_initializer\n    dtype)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 387, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 283, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,4,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Variable_70/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_70/Assign\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_70/Adam, Variable_70/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,4,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Variable_70/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_70/Assign\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_70/Adam, Variable_70/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-e590fa8f669f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-288a7b198bb2>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-b037ce24a0a1>\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0msummary_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mcoord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,4,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Variable_70/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_70/Assign\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_70/Adam, Variable_70/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Variable_70/Adam/Assign', defined at:\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tornado\\ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-e590fa8f669f>\", line 1, in <module>\n    main(_)\n  File \"<ipython-input-36-288a7b198bb2>\", line 2, in main\n    run_training()\n  File \"<ipython-input-35-b48a4403a598>\", line 20, in run_training\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(perdidas)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 424, in minimize\n    name=name)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 600, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 1150, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 181, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 155, in create_slot_with_initializer\n    dtype)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 387, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 283, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\rober\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,4,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Variable_70/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_70/Assign\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_70/Adam, Variable_70/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "main(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
