{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   VERSIÓN 1.0: FICHERO QUE SE ENCARGA DE GENERAR LOS TFRECORDS                                                                                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos todos los imports necesarios para que nuestros ficheros funcionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.io as sio\n",
    "import os, os.path\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import scipy.ndimage\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ruta de los ficheros que contienen nuestras imagenes médicas de los pacientes, para los ficheros \"tfrecords\" de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\Practicas\\training\\training_v2.tfrecords\n",
      "C:\\Users\\rober\\Practicas\\training\\validation_v2.tfrecords\n"
     ]
    }
   ],
   "source": [
    "path_tfrecords_train = os.path.join(\"C:\", \"\\\\Users\\\\rober\\\\Practicas\\\\training\\\\training_v2.tfrecords\")\n",
    "print(path_tfrecords_train)\n",
    "path_tfrecords_validation = os.path.join(\"C:\", \"\\\\Users\\\\rober\\\\Practicas\\\\training\\\\validation_v2.tfrecords\")\n",
    "print(path_tfrecords_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función encargada de mostrar el progreso de la lectura de imagenes de cada canal(t1,t2,t1ce,flair) de cada paciente del número total de pacientes que tengamos para cada conjunto de datos(training,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(count, total):\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count) / total\n",
    "\n",
    "    # Status-message.\n",
    "    # Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte de código encargada de obtener los path relativos al HGG y al LGG, y a continuación realizar el congunto de datos para cada parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hábria que hacer que esto fuera totalmente aleatorio, añadir el conjunto de datos para el test y aplicar porcentajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pacientes en el directorio HGG: 210\n",
      "Número de pacientes en el directorio LGG: 75\n",
      "\n",
      "\n",
      "DIRECTORIO DE ENTRENAMIENTO\n",
      "Índice,Directorio Paciente\n",
      "(0, 'C:\\\\Users\\\\rober\\\\Practicas\\\\MICCAI_BraTS17_Data_Training\\\\HGG\\\\Brats17_2013_10_1')\n",
      "(1, 'C:\\\\Users\\\\rober\\\\Practicas\\\\MICCAI_BraTS17_Data_Training\\\\LGG\\\\Brats17_2013_0_1')\n",
      "\n",
      "\n",
      "DIRECTORIO DE VALIDATION\n",
      "Índice,Directorio Paciente\n",
      "(0, 'C:\\\\Users\\\\rober\\\\Practicas\\\\MICCAI_BraTS17_Data_Training\\\\HGG\\\\Brats17_TCIA_608_1')\n",
      "(1, 'C:\\\\Users\\\\rober\\\\Practicas\\\\MICCAI_BraTS17_Data_Training\\\\LGG\\\\Brats17_TCIA_654_1')\n"
     ]
    }
   ],
   "source": [
    "directorioHGG = glob.glob('C:\\\\Users\\\\rober\\\\Practicas\\\\MICCAI_BraTS17_Data_Training\\\\HGG\\\\*')\n",
    "directorioLGG = glob.glob('C:\\\\Users\\\\rober\\\\Practicas\\\\MICCAI_BraTS17_Data_Training\\\\LGG\\\\*')\n",
    "print(\"Número de pacientes en el directorio HGG:\",len(directorioHGG))\n",
    "print(\"Número de pacientes en el directorio LGG:\",len(directorioLGG))\n",
    "print(\"\\n\")\n",
    "directorio_entrenamiento = directorioHGG[:-209] + directorioLGG[:-74]\n",
    "directorio_validation = directorioHGG[-1:]+directorioLGG[-1:]\n",
    "print(\"DIRECTORIO DE ENTRENAMIENTO\")\n",
    "print(\"Índice,Directorio Paciente\")\n",
    "for i in enumerate(directorio_entrenamiento):\n",
    "    print(i)\n",
    "print(\"\\n\")\n",
    "print(\"DIRECTORIO DE VALIDATION\")\n",
    "print(\"Índice,Directorio Paciente\")\n",
    "for i in enumerate(directorio_validation):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjunto de funciones definidas para el autor necesarias para realizar la conversión de los datos a \"TFRecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_image_by_patient(imname):\n",
    "        im = sitk.GetArrayFromImage(sitk.ReadImage(imname)).astype(np.float32)\n",
    "        return (im - im.mean()) / im.std()\n",
    "        roi_index = im > 0\n",
    "        mean = im[roi_index].mean()\n",
    "        std = im[roi_index].std()\n",
    "        im[roi_index] -= mean\n",
    "        im[roi_index] /= std\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLabel(label, d):\n",
    "        if np.count_nonzero(label[d]) > 0:\n",
    "            return True, 1\n",
    "        else:\n",
    "            return False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _processing_image(seq, label, depth):\n",
    "        seqs = []\n",
    "        labs = []\n",
    "        for d in [depth-2, depth-1, depth]:\n",
    "            label_data = label[d]\n",
    "            labs.append(np.array(label_data))\n",
    "            mod = []\n",
    "            for im in seq:\n",
    "                image_data = im[d]\n",
    "                #image_data = scipy.ndimage.interpolation.zoom(image_data, 2, order=1, mode='nearest')\n",
    "                # upsample \n",
    "                mod.append(image_data)\n",
    "            seqs.append(np.array(mod))\n",
    "        seqs = np.array(seqs)\n",
    "        labs = np.array(labs)\n",
    "        return seqs.tobytes(), labs.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _processing_image_single(seq, label, depth):\n",
    "        mod = []\n",
    "        for im in seq:\n",
    "            image_data = im[depth]\n",
    "            #image_data = scipy.ndimage.interpolation.zoom(image_data, 2, order=1, mode='nearest')\n",
    "            # upsample \n",
    "            mod.append(image_data)\n",
    "        mod = np.array(mod)\n",
    "        label_data = label[depth]\n",
    "        # upsample\n",
    "        #label_data = scipy.ndimage.interpolation.zoom(label_data, 2, order=1, mode='nearest')\n",
    "        shape = list(mod.shape)\n",
    "        #if (mod.shape[0] != 4 or mod.shape[1] != 240 or mod.shape[2] != 240):\n",
    "        #\tprint(shape)\n",
    "        #\tprint(\"SHIT\")\n",
    "        #\texit()\n",
    "        # 4,240,240\n",
    "        return mod.tobytes(), label_data.tobytes(), shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SythText datasets is too big to store in a record. \n",
    "## So Transform tfrecord according to dir name\n",
    "\n",
    "def _convert_to_example(image_data, label):\n",
    "        #print 'shape: {}, height:{}, width:{}'.format(shape,shape[0],shape[1])\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image/encoded': bytes_feature(image_data),\n",
    "                'label/encoded': bytes_feature(label)\n",
    "                }))\n",
    "        return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función auxiliar para encapsular un float y guardarlo en el archivo TFRecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_feature(value):\n",
    "    \"\"\"Wrapper for inserting float features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    if (type(value[0]) == np.float32):\n",
    "        value = [v.item() for v in value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función auxiliar para encapsular los bytes y guardarlos en el archivo TFRecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_feature(value):\n",
    "    \"\"\"Wrapper for inserting bytes features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función encargada de generar los \"TFRecords para el conjunto del Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Progress: 0.0%\n",
      "\n",
      "0 C:\\Users\\rober\\Practicas\\MICCAI_BraTS17_Data_Training\\HGG\\Brats17_2013_10_1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-50b4b9932d12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                     \u001b[1;31m#En este bucle procesamos las imagenes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                     \u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_processing_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                     \u001b[1;31m#Convertimos las imagenes y las etiquetas procesadas en el objetos de tipo \"Example\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                     \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_to_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seq' is not defined"
     ]
    }
   ],
   "source": [
    "# Abre un TFRecordWriter para el archivo de salida\n",
    "with tf.python_io.TFRecordWriter(path_tfrecords_train) as writer:\n",
    "    #Lista donde almacenaremos todos los objetos \"Example\"\n",
    "    all_example = []\n",
    "    #Bucle que se encarga de recorrer los pacioentes\n",
    "    for i,path in enumerate(directorio_entrenamiento):\n",
    "        #Mostramos por pantalla el progreso que llevamos \n",
    "        print_progress(count = i, total = len(directorio_entrenamiento)-1)\n",
    "        print(\"\\n\")\n",
    "        #Mostramos el Indice y el paciente actual\n",
    "        print(i,path)\n",
    "        #Como índica su nombre es el directorio del paciente actual\n",
    "        directorio_paciente = glob.glob(path + '\\\\*')\n",
    "        #Bucle que se encarga de recorrer los ficheros del paciente actual\n",
    "        for(j,path_paciente) in enumerate(directorio_paciente):\n",
    "            #print(j,path_paciente)\n",
    "            #Leemos el fichero relacionado con el tipo \"Flair\"\n",
    "            if path_paciente.endswith(\"flair.nii.gz\"):\n",
    "                #print(\"Entra en flair\")\n",
    "                flair = glob.glob(path_paciente)\n",
    "                norm_flair = norm_image_by_patient(flair[0])\n",
    "            #Leemos el fichero relacionado con el tipo \"T2\"\n",
    "            if path_paciente.endswith(\"t2.nii.gz\"):\n",
    "                #print(\"Entra en t2\")\n",
    "                t2 = glob.glob(path_paciente)\n",
    "                norm_t2 = norm_image_by_patient(t2[0])\n",
    "            #Leemos el fichero relacionado con el tipo \"T1\"\n",
    "            if path_paciente.endswith(\"t1.nii.gz\"):\n",
    "                #print(\"Entra en t1\")\n",
    "                t1 = glob.glob(path_paciente)\n",
    "                norm_t1 = norm_image_by_patient(t1[0])\n",
    "            #Leemos el fichero relacionado con el tipo \"SEG\"\n",
    "            #Este es especial porque es la etiqueta donde están la segmentación hecha por el médico\n",
    "            if path_paciente.endswith(\"seg.nii.gz\"):\n",
    "                #print(\"Entra en seg\")\n",
    "                label = glob.glob(path_paciente)[0]\n",
    "                label = sitk.GetArrayFromImage(sitk.ReadImage(label)).astype(np.float32)\n",
    "                #Leemos el fichero relacionado con el tipo \"T1CE\"\n",
    "            if path_paciente.endswith(\"t1ce.nii.gz\"):\n",
    "                #print(\"Entra en t1ce\")\n",
    "                t1ce = glob.glob(path_paciente)\n",
    "                norm_t1ce = norm_image_by_patient(t1ce[0])\n",
    "        #Comprobamos que cada canal se haya normalizado correctamente \n",
    "        if((len(norm_flair) == 0) or (len(norm_t2) == 0) or (len(norm_t1) == 0) or (len(norm_t1ce) == 0)):\n",
    "            seq = [norm_flair,norm_t2,norm_t1,norm_t1ce]\n",
    "        else:\n",
    "            ind = 0\n",
    "            for depth in range(2,155):\n",
    "                #Comprobamos las etiquetas\n",
    "                is_valid, sample_num = checkLabel(label, depth)\n",
    "                if ( not is_valid):\n",
    "                    continue\n",
    "                for i in range(sample_num):\n",
    "                    #En este bucle procesamos las imagenes\n",
    "                    image_data, label_data = _processing_image(seq, label, depth)\n",
    "                    #Convertimos las imagenes y las etiquetas procesadas en el objetos de tipo \"Example\"\n",
    "                    example = _convert_to_example(image_data, label_data)\n",
    "                    #Indexamos el objeto convertido a la lista de objetos\n",
    "                    all_example.append(example)\n",
    "                #print(\"All_example_len\",len(all_example))\n",
    "        #Mostramos los cortes\n",
    "        print(\"Cortes:\", len(all_example))\n",
    "        #Barajamos los cortes de forma aleatoria\n",
    "        shuffle(all_example)\n",
    "        #Bucle encargado de serializar la información y escribrla en un fichero \"TFRecord\"\n",
    "        for ex in all_example:\n",
    "            writer.write(ex.SerializeToString()) \n",
    "    print ('Transformación Realizada Completamente!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función encargada de generar los \"TFRecords para el conjunto del Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre un TFRecordWriter para el archivo de salida\n",
    "with tf.python_io.TFRecordWriter(path_tfrecords_validation) as writer:\n",
    "    #Lista donde almacenaremos todos los objetos \"Example\"\n",
    "    all_example = []\n",
    "    #Bucle que se encarga de recorrer los pacioentes\n",
    "    for i,path in enumerate(directorio_entrenamiento):\n",
    "        #Mostramos por pantalla el progreso que llevamos \n",
    "        print_progress(count = i, total = len(directorio_entrenamiento)-1)\n",
    "        print(\"\\n\")\n",
    "        #Mostramos el Indice y el paciente actual\n",
    "        print(i,path)\n",
    "        #Como índica su nombre es el directorio del paciente actual\n",
    "        directorio_paciente = glob.glob(path + '\\\\*')\n",
    "        #Bucle que se encarga de recorrer los ficheros del paciente actual\n",
    "        for(j,path_paciente) in enumerate(directorio_paciente):\n",
    "            #print(j,path_paciente)\n",
    "            #Leemos el fichero relacionado con el tipo \"Flair\"\n",
    "            if path_paciente.endswith(\"flair.nii.gz\"):\n",
    "                #print(\"Entra en flair\")\n",
    "                flair = glob.glob(path_paciente)\n",
    "                norm_flair = norm_image_by_patient(flair[0])\n",
    "            #Leemos el fichero relacionado con el tipo \"T2\"      \n",
    "            if path_paciente.endswith(\"t2.nii.gz\"):\n",
    "                #print(\"Entra en t2\")\n",
    "                t2 = glob.glob(path_paciente)\n",
    "                norm_t2 = norm_image_by_patient(t2[0])\n",
    "            #Leemos el fichero relacionado con el tipo \"T1\"    \n",
    "            if path_paciente.endswith(\"t1.nii.gz\"):\n",
    "                #print(\"Entra en t1\")\n",
    "                t1 = glob.glob(path_paciente)\n",
    "                norm_t1 = norm_image_by_patient(t1[0])\n",
    "            #Leemos el fichero relacionado con el tipo \"SEG\"\n",
    "            #Este es especial porque es la etiqueta donde están la segmentación hecha por el médico\n",
    "            if path_paciente.endswith(\"seg.nii.gz\"):\n",
    "                #print(\"Entra en seg\")\n",
    "                label = glob.glob(path_paciente)[0]\n",
    "                label = sitk.GetArrayFromImage(sitk.ReadImage(label)).astype(np.float32)\n",
    "            #Leemos el fichero relacionado con el tipo \"T1CE\"\n",
    "            if path_paciente.endswith(\"t1ce.nii.gz\"):\n",
    "                #print(\"Entra en t1ce\")\n",
    "                t1ce = glob.glob(path_paciente)\n",
    "                norm_t1ce = norm_image_by_patient(t1ce[0])\n",
    "        #Comprobamos que cada canal se haya normalizado correctamente        \n",
    "        if((len(norm_flair) == 0) or (len(norm_t2) == 0) or (len(norm_t1) == 0) or (len(norm_t1ce) == 0)):\n",
    "            print(\"ERROR FALTA ALGUNA DE LAS COMPONENTES\")\n",
    "            print(len(norm_flair),len(norm_t2),len(norm_t1),len(norm_t1ce))\n",
    "        else:\n",
    "            seq = [norm_flair,norm_t2,norm_t1,norm_t1ce]\n",
    "            ind = 0\n",
    "            for depth in range(155):\n",
    "                ind += 1\n",
    "                #Procesamos la imagen y la etiqueta\n",
    "                image_data, label_data, shape = _processing_image_single(seq, label, depth)\n",
    "                #Convertimos las imagenes y las etiquetas procesadas en el objetos de tipo \"Example\"\n",
    "                example = _convert_to_example(image_data, label_data)\n",
    "                #Serializamos la información y la escribimos en un fichero \"TFRecord\"\n",
    "                writer.write(example.SerializeToString())\n",
    "    print ('Transformación Realizada Completamente!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
